<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.11"/>
<title>digitLearning: src.neuralNetwork.NeuralNetwork Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">digitLearning
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Main&#160;Page</span></a></li>
      <li><a href="namespaces.html"><span>Namespaces</span></a></li>
      <li class="current"><a href="annotated.html"><span>Classes</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
  <div id="navrow2" class="tabs2">
    <ul class="tablist">
      <li><a href="annotated.html"><span>Class&#160;List</span></a></li>
      <li><a href="classes.html"><span>Class&#160;Index</span></a></li>
      <li><a href="functions.html"><span>Class&#160;Members</span></a></li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>src</b></li><li class="navelem"><a class="el" href="namespacesrc_1_1neuralNetwork.html">neuralNetwork</a></li><li class="navelem"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html">NeuralNetwork</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classsrc_1_1neuralNetwork_1_1NeuralNetwork-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">src.neuralNetwork.NeuralNetwork Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a72b80835f72acc3c6bff018dd2f9f1a7"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a72b80835f72acc3c6bff018dd2f9f1a7">__init__</a> (self, len_layers, squishing_funcs, dir_load)</td></tr>
<tr class="separator:a72b80835f72acc3c6bff018dd2f9f1a7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad6349ea5f03d3ab38aa0ed4cd27a01b8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#ad6349ea5f03d3ab38aa0ed4cd27a01b8">initializeWeightsBiases</a> (self, dir_load)</td></tr>
<tr class="separator:ad6349ea5f03d3ab38aa0ed4cd27a01b8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a3877f22a5f71a46ecbac86894ea8d426"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a3877f22a5f71a46ecbac86894ea8d426">initializeEmptyDParamArrays</a> (self)</td></tr>
<tr class="separator:a3877f22a5f71a46ecbac86894ea8d426"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca6c479de85d60a5637164b7579bebc0"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#aca6c479de85d60a5637164b7579bebc0">trainNEO</a> (self, training_data, batch_size, gradientDescentFactor, repeat)</td></tr>
<tr class="separator:aca6c479de85d60a5637164b7579bebc0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5c9936546fa398f9c30c17651293d8c"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#ac5c9936546fa398f9c30c17651293d8c">calculateNegGradientNEO</a> (self, in_out_layers, gdfactor)</td></tr>
<tr class="separator:ac5c9936546fa398f9c30c17651293d8c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a783b7b81a9427e302728b02ade980d18"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a783b7b81a9427e302728b02ade980d18">train</a> (self, training_data, batch_size, gradientDescentFactor, repeat)</td></tr>
<tr class="separator:a783b7b81a9427e302728b02ade980d18"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8bbfff35ec6a3a467bf1e39a37babae8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a8bbfff35ec6a3a467bf1e39a37babae8">derivativeCostToParam</a> (self, index, a, der_func_z, der_cost_to_a)</td></tr>
<tr class="separator:a8bbfff35ec6a3a467bf1e39a37babae8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a06baba93e5a4486e008c739f4492b66f"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a06baba93e5a4486e008c739f4492b66f">calculateNegGradient</a> (self, in_out_layers)</td></tr>
<tr class="separator:a06baba93e5a4486e008c739f4492b66f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa315683b512adf945bf1fd54b177dc40"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#aa315683b512adf945bf1fd54b177dc40">generateOuputLayer</a> (self, input_layer)</td></tr>
<tr class="separator:aa315683b512adf945bf1fd54b177dc40"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:adde0d575e9f40dd7740fcb712b293002"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#adde0d575e9f40dd7740fcb712b293002">generateAllLayers</a> (self, input_layer)</td></tr>
<tr class="separator:adde0d575e9f40dd7740fcb712b293002"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab287315a1443d6cbf3c6b405a5035be8"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#ab287315a1443d6cbf3c6b405a5035be8">generateInputLayer</a> (self, output_layer)</td></tr>
<tr class="separator:ab287315a1443d6cbf3c6b405a5035be8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a30341b6e19d739fb71b1d0370b72b903"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a30341b6e19d739fb71b1d0370b72b903">save</a> (self, dir_save)</td></tr>
<tr class="separator:a30341b6e19d739fb71b1d0370b72b903"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8043e1545c08fb9a9215d83ba021bd32"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a8043e1545c08fb9a9215d83ba021bd32">test</a> (self, testing_data)</td></tr>
<tr class="separator:a8043e1545c08fb9a9215d83ba021bd32"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a819389f2ec6231ffdccf186e3f32eb9d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classsrc_1_1neuralNetwork_1_1NeuralNetwork.html#a819389f2ec6231ffdccf186e3f32eb9d">inform</a> (self, args, error_rate, average_cost)</td></tr>
<tr class="separator:a819389f2ec6231ffdccf186e3f32eb9d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a0f8b52022c64b3ee2cea1d1606b65da4"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a0f8b52022c64b3ee2cea1d1606b65da4"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>nb_layer</b></td></tr>
<tr class="separator:a0f8b52022c64b3ee2cea1d1606b65da4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8346128fedcd7a85f7b829ab91ae3a36"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a8346128fedcd7a85f7b829ab91ae3a36"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>len_layers</b></td></tr>
<tr class="separator:a8346128fedcd7a85f7b829ab91ae3a36"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeb0760fbe24ae24b183921b6104de2c7"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeb0760fbe24ae24b183921b6104de2c7"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>weights</b></td></tr>
<tr class="separator:aeb0760fbe24ae24b183921b6104de2c7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d2938841ec5e36a2246c80ad0d63385"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="a6d2938841ec5e36a2246c80ad0d63385"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>biases</b></td></tr>
<tr class="separator:a6d2938841ec5e36a2246c80ad0d63385"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aeefddd4ccdf67a01d745475e3b59c23f"><td class="memItemLeft" align="right" valign="top"><a class="anchor" id="aeefddd4ccdf67a01d745475e3b59c23f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>squishing_funcs</b></td></tr>
<tr class="separator:aeefddd4ccdf67a01d745475e3b59c23f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">    Class neural network.
</pre> </div><h2 class="groupheader">Constructor &amp; Destructor Documentation</h2>
<a class="anchor" id="a72b80835f72acc3c6bff018dd2f9f1a7"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.__init__ </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>len_layers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>squishing_funcs</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dir_load</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Initialize an object NeuralNetwork.

    Inputs :

    -&gt; entry : STRING variable that is the name of a txt document.
      This document contains all the information concerning
      the layers and their sizes. It will be used as followed :
      "./main.py information.txt"
      ex of entry : network1.txt
</pre> 
</div>
</div>
<h2 class="groupheader">Member Function Documentation</h2>
<a class="anchor" id="a06baba93e5a4486e008c739f4492b66f"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.calculateNegGradient </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>in_out_layers</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to train the neural network.

    Inputs :

    -&gt; inOutLayers : a TUPLE that contains two numpy arrays
          the first numpy array has a length of 28x28 = 784
          each element is in [0, 1] 0 means a dark pixel
          and 1 means a white pixel
          the second numpy array has length of 10.
          This is the best output that could be obtain when
          we test the neural network with the according image

    Output :

    &lt;- (dweights, dbiases) : TUPLE of LISTS.
          The first one contains NUMPY MATRIX for all the
          weight matrix in the neural network.
          The second one contains NUMPY ARRAY for all the
          biases array in the neural network.
</pre> 
</div>
</div>
<a class="anchor" id="ac5c9936546fa398f9c30c17651293d8c"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.calculateNegGradientNEO </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>in_out_layers</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gdfactor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to train the neural network.

    Inputs :

    -&gt; inOutLayers : a TUPLE that contains two numpy arrays
          the first numpy array has a length of 28x28 = 784
          each element is in [0, 1] 0 means a dark pixel
          and 1 means a white pixel
          the second numpy array has length of 10.
          This is the best output that could be obtain when
          we test the neural network with the according image
</pre> 
</div>
</div>
<a class="anchor" id="a8bbfff35ec6a3a467bf1e39a37babae8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.derivativeCostToParam </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>index</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>a</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>der_func_z</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>der_cost_to_a</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Optimized calculation for derivative of the cost function according
    to the following parameters : bias, weight and a.

    Complexity : (column+1) * row
</pre> 
</div>
</div>
<a class="anchor" id="adde0d575e9f40dd7740fcb712b293002"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.generateAllLayers </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_layer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used when training the neural network model by giving it a
    array that contains all the pixels from an handwriting image.
    Each step consists in calculating f(A_i x_i + b_i) = x_(i+1).
    A_i is a weight matrix, b_i is a biases vector, x_i is the neural
    vector or layer of index i and x_(i+1) of index (i+1).

    Input :

    -&gt; input_layer : NUMPY ARRAY which len is 784.
             it contains the color of pixel (white / black) with
             number notation from 0 to 1 (everything was divided
             by 255)

    Output :

    &lt;- values_layers : LIST of NUMPY ARRAY for each layer in the neural
             network (they all have different sizes) which size
             is nb_layer + 2.
             This will be used to calculate the
             negative gradient and therefore to do the back
             propagation. Thus values_layers[self.nb_layer+1] is
             a NUMPY ARRAY of size 10.
             ex : [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] in the best
             case scenario if the input is a handwriting five.

    &lt;- z_values :    LIST of NUMPY ARRAY for each layer in the neural
             network minus one (except the first one).
             Thus its size is nb_layer+1.
</pre> 
</div>
</div>
<a class="anchor" id="ab287315a1443d6cbf3c6b405a5035be8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.generateInputLayer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>output_layer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to generate an input of the neural network.
    This input can by used after to reconstitute an image thanks to the
    function writeMNISTimage in mnistHandwriting.py using
    Python Image Library.
    Each step consists in calculating x_i=A_i^(-1)[f^(-1)(x_(i+1))-b_i].
    A_i is a weight matrix, b_i is a biases vector, x_i is the neural
    vector or layer of index i and x_(i+1) of index (i+1).

    Inputs :

    -&gt; output_layer : NUMPY ARRAY of size 10. Each element is in
             [0, 1]. ex : [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]

    Output :

    &lt;- new_array   : NUMPY ARRAY which len is 784.
             it contains the color of pixel (white / black) with
             number notation from 0 to 1
</pre> 
</div>
</div>
<a class="anchor" id="aa315683b512adf945bf1fd54b177dc40"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.generateOuputLayer </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>input_layer</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to test the neural network model by giving it an array
    that contains all the pixels from an handwriting image. Use the same
    principle as generateAllLayers method.

    Input :

    -&gt; input_layer : NUMPY ARRAY which len is 784.
             it contains the color of pixel (white / black) with
             number notation from 0 to 1 (everything was divided
             by 255)

    Output :

    &lt;-output_layer : NUMPY ARRAY of size 10.
             ex : [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] in the best
             case scenario if the input is a handwriting five.
</pre> 
</div>
</div>
<a class="anchor" id="a819389f2ec6231ffdccf186e3f32eb9d"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.inform </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>args</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>error_rate</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>average_cost</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method to load information in the CSV file in the correspondant
    directory.
</pre> 
</div>
</div>
<a class="anchor" id="a3877f22a5f71a46ecbac86894ea8d426"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.initializeEmptyDParamArrays </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to do the initialization of dw and db
    for the method train.
</pre> 
</div>
</div>
<a class="anchor" id="ad6349ea5f03d3ab38aa0ed4cd27a01b8"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.initializeWeightsBiases </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dir_load</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to initialize the matrix weights and the vectors biases.
    If load == None, it means that this will not load weights and biases
    Else load == "dir/doc.txt" load weight and biases from that doc
</pre> 
</div>
</div>
<a class="anchor" id="a30341b6e19d739fb71b1d0370b72b903"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.save </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>dir_save</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to save the neural network.
    In fact, it simply writes every matrix weights and biases in the
    document named doc_save.

    Moreover, this function also writes information about the
    size of the training data used to train the model during the
    execution and
</pre> 
</div>
</div>
<a class="anchor" id="a8043e1545c08fb9a9215d83ba021bd32"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.test </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>testing_data</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to test the neural network after its training.
</pre> 
</div>
</div>
<a class="anchor" id="a783b7b81a9427e302728b02ade980d18"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.train </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>training_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gradientDescentFactor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>repeat</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to train the neural network.

    If batch_size == 1 =&gt; individual training
    Else               =&gt; mini_batching training

    Repeat is the number of repetition of learning for each batch.
</pre> 
</div>
</div>
<a class="anchor" id="aca6c479de85d60a5637164b7579bebc0"></a>
<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def src.neuralNetwork.NeuralNetwork.trainNEO </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>training_data</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>batch_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>gradientDescentFactor</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>repeat</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">    Method used to train the neural network.

    If batch_size == 1 =&gt; individual training
    Else               =&gt; mini_batching training

    Repeat is the number of repetition of learning for each batch.
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>/home/alexandre/Documents/python/digitLearning/src/neuralNetwork.py</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by &#160;<a href="http://www.doxygen.org/index.html">
<img class="footer" src="doxygen.png" alt="doxygen"/>
</a> 1.8.11
</small></address>
</body>
</html>
